# docker-compose.prod.yaml
# docker compose -f docker-compose.test.yaml up -d --build
# aliases suffix is -test
services:
  wine_host: # this is the name of the service and name of the host (POSTGRES_HOST)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    # -----------------------------
    restart: unless-stopped
    container_name: ${POSTGRES_HOST}
    image: ghcr.io/alexanderjkochnev/postgres:17-alpine
    command: >
      postgres
      -c shared_buffers=16GB
      -c effective_cache_size=48GB
      -c maintenance_work_mem=2GB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=32MB
      -c min_wal_size=1GB
      -c max_wal_size=8GB
      -c max_worker_processes=14
      -c max_parallel_workers_per_gather=2
      -c max_connections=200
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    expose:
      - "${POSTGRES_PORT}"
    volumes:
      - ./pg_data:/var/lib/postgresql/data
      - ./pg_dump:/tmp

    healthcheck:
      test: |
        sh -c 'pg_isready -h localhost -p ${POSTGRES_PORT} -U ${POSTGRES_USER} -d ${POSTGRES_DB}'
      # минимальная конфигурация для того что бы не было проблем с role root doesnnot exists
      interval: 10s # 1m30s
      timeout: 10s
      retries: 5
      start_period: 40s
      start_interval: 5s
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 20G
        reservations:
          cpus: '2'
          memory: 16G
    networks:
      - internal_network
  
  adminer:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    container_name: pg_admin
    # image: adminer:4.8.1
    image: ghcr.io/alexanderjkochnev/adminer:4.8.1
    restart: unless-stopped
    environment:
      - ADMINER_PLUGINS=tables-filter enum-option enum-types
      - ADMINER_DESIGN=nette
    depends_on:
      - wine_host
    ports:
      - "${ADMINER_PORTS}"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.12'
          memory: 256M
    networks:
      - internal_network
  
  app:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    container_name: ${APP_CONTAINER_NAME}
    build: .
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port ${API_PORT} --loop uvloop --workers 56
    depends_on:
      pgbouncer:
        condition: service_healthy
      wine_host:
        condition: service_healthy
      mongo:
        condition: service_healthy
    expose:
      - ${API_PORT}
    environment:
      # POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_HOST: pgbouncer-${ALIASE}
      WEB_PORT: 6432
      # WEB_PORT: ${API_PORT}
      WEB_HOST: pgbouncer-${ALIASE}
      BASE_URL: ${BASE_URL}
      NODE_ENV: production
      OLLAMA_HOST: http://ollama:11434
    volumes:
      - ./templates:/app/templates
      - ./migration_volume:/app/app/migration/versions
      - ./upload_volume:/app/upload_volume
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 20G
        reservations:
          cpus: '2'
          memory: 16G
    networks:
      shared_network:
        aliases:
          - app-test
      internal_network:
  
  mongo:
    # --- НАСТРОЙКИ ЛОГИРОВАНИЯ ---
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    # -----------------------------
    image: ghcr.io/alexanderjkochnev/mongo:4.4.20
    container_name: ${MONGODB_CONTAINER_NAME}
    hostname: ${MONGO_HOSTNAME}
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
      MONGO_INITDB_DATABASE: admin
    expose:
      - "${MONGO_INN_PORT}"
    volumes:
      - ./mongodb_data:/data/db
      - ./mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    command: >
      mongod
      --bind_ip_all
      --wiredTigerCacheSizeGB 4
      --storageEngine wiredTiger
      --journalCommitInterval 500
      --syncdelay 300
      --nojournal
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | ${MONGODB_CONTAINER_NAME} localhost:${MONGO_INN_PORT}/admin --quiet --username admin --password admin
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - internal_network

  
  mongo-express:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    image: ghcr.io/alexanderjkochnev/mongo-express
    container_name: ${MONGO_EXPRESS_CONTAINER_NAME}
    restart: unless-stopped
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${ME_CONFIG_MONGODB_ADMINUSERNAME}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${ME_CONFIG_MONGODB_ADMINPASSWORD}
      ME_CONFIG_MONGODB_SERVER: ${ME_CONFIG_MONGODB_SERVER}
      ME_CONFIG_BASICAUTH_USERNAME: ${ME_CONFIG_BASICAUTH_USERNAME}
      ME_CONFIG_BASICAUTH_PASSWORD: ${ME_CONFIG_BASICAUTH_PASSWORD}
    ports:
      - "${ME_OUT_PORT}:${ME_INN_PORT}"
    depends_on:
      wine_host:
        condition: service_healthy
      mongo:
        condition: service_healthy
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:${ME_INN_PORT}" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 512M
        reservations:
          cpus: '0.250'
          memory: 256M
    networks:
      internal_network
  
  preact_front:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    build:
      context: ./preact_front          # путь к папке с Preact
      dockerfile: Dockerfile           # имя Dockerfile внутри ./preact_front
    container_name: ${PREACT_CONTAINER_NAME}
    expose:
      - "80"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    restart: unless-stopped
    networks:
      shared_network:
        aliases:
          - preact_front-test
      internal_network:
  
  pgbouncer:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    image: edoburu/pgbouncer:latest
    container_name: ${PGBOUNCER_CONTAINER_NAME}
    environment:
      DB_HOST: wine_host-${ALIASE}
      DB_PORT: 5432
      DB_USER: wine
      DB_PASSWORD: wine1
      DB_NAME: wine_db
      AUTH_TYPE: scram-sha-256
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 500
      SERVER_IDLE_TIMEOUT: 600
      QUERY_TIMEOUT: 60
      DEFAULT_POOL_SIZE: 50
      MIN_POOL_SIZE: 20
      RESERVE_POOL_SIZE: 10
      LISTEN_PORT: 6432
      ADMIN_USERS: wine
      # ВАЖНО: Явно создаем userlist через переменные
      AUTH_FILE: /etc/pgbouncer/userlist.txt
      # Дополнительные пользователи (если нужны)
      USERS: "wine wine1"
    expose:
      - "6432"  # Порт для приложения
    restart: unless-stopped
    healthcheck:
      # Официальный способ проверки pgbouncer (внутри образа есть psql-client)
      test: ["CMD", "pg_isready", "-h", "localhost", "-p", "6432", "-U", "wine", "-d", "wine_db"]
      interval: 5s
      timeout: 5s
      retries: 5
    depends_on:
      wine_host:
        condition: service_healthy
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    networks:
      internal_network:
    
  ollama:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    image: ollama/ollama
    container_name: ${OLLAMA_CONTAINER_NAME}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    volumes:
      - ollama_data:/root/.ollama
    networks:
      internal_network:

volumes:
  migration_volume: # alembic migrations
  pg_data: # postgresql data
  pg_dump: # postgres dump/restore
  mongodb_data:
  upload_volume:
  certs_data:
  certbot_www:
  ollama_data:

networks:
  internal_network:
    driver: bridge
  shared_network:
    external: true