# docker-compose.prod.yaml
# docker compose -f docker-compose.xeon.yaml up -d --build
# aliases suffix is -xeon
services:
  wine_host: # this is the name of the service and name of the host (POSTGRES_HOST)
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    # -----------------------------
    restart: unless-stopped
    container_name: ${POSTGRES_HOST}-${ALIASE}
    image: ghcr.io/alexanderjkochnev/postgres:17-alpine
    command: >
      postgres
      -c shared_buffers=16GB
      -c effective_cache_size=48GB
      -c maintenance_work_mem=2GB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=32MB
      -c min_wal_size=1GB
      -c max_wal_size=8GB
      -c max_worker_processes=14
      -c max_parallel_workers_per_gather=2
      -c max_connections=200
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    expose:
      - "${POSTGRES_PORT}"
    volumes:
      - ./pg_data:/var/lib/postgresql/data
      - ./pg_dump:/tmp

    healthcheck:
      test: |
        sh -c 'pg_isready -h localhost -p ${POSTGRES_PORT} -U ${POSTGRES_USER} -d ${POSTGRES_DB}'
      # минимальная конфигурация для того что бы не было проблем с role root doesnnot exists
      interval: 10s # 1m30s
      timeout: 10s
      retries: 5
      start_period: 40s
      start_interval: 5s
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 20G
        reservations:
          cpus: '2'
          memory: 16G
    networks:
      - internal-net
      
  app:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    container_name: app-${ALIASE}
    build: .
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port ${API_PORT} --loop auto --workers 56
    depends_on:
      # !!!!!!!!!!!!!!  ИМЯ СЕРВИСА ПРАВИТЬ ВРУЧНУЮ !!!!!
      pgbouncer-xeon:
        condition: service_healthy
      wine_host:
        condition: service_healthy
      mongo:
        condition: service_healthy
    expose:
      - ${API_PORT}
    environment:
      # POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_HOST: pgbouncer-${ALIASE}
      WEB_PORT: 6432
      # WEB_PORT: ${API_PORT}
      WEB_HOST: pgbouncer-${ALIASE}
      # WEB_HOST: ${API_HOST}
      BASE_URL: ${BASE_URL}
      NODE_ENV: production
      OLLAMA_HOST: http://ollama:11434
    volumes:
      - ./templates:/app/templates
      - ./migration_volume:/app/app/migration/versions
      - ./upload_volume:/app/upload_volume
    deploy:
      resources:
        limits:
          cpus: '8'
          memory: 20G
        reservations:
          cpus: '2'
          memory: 16G
    networks:
      - internal-net
      - shared_network
  
  mongo:
    # --- НАСТРОЙКИ ЛОГИРОВАНИЯ ---
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    # -----------------------------
    image: ghcr.io/alexanderjkochnev/mongo:4.4.20
    container_name: mongo-${ALIASE}
    hostname: ${MONGO_HOSTNAME}
    restart: unless-stopped
    environment:
      MONGO_INITDB_ROOT_USERNAME: admin
      MONGO_INITDB_ROOT_PASSWORD: admin
      MONGO_INITDB_DATABASE: admin
    expose:
      - "${MONGO_INN_PORT}"
    volumes:
      - ./mongodb_data:/data/db
      - ./mongo/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    command: >
      mongod
      --bind_ip_all
      --wiredTigerCacheSizeGB 4
      --storageEngine wiredTiger
      --journalCommitInterval 500
      --syncdelay 300
      --nojournal
    healthcheck:
      test: echo 'db.runCommand("ping").ok' | mongo localhost:${MONGO_INN_PORT}/admin --quiet --username admin --password admin
      interval: 10s
      timeout: 10s
      retries: 30
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - internal-net

  preact_front:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    build:
      context: ./preact_front          # путь к папке с Preact
      dockerfile: Dockerfile           # имя Dockerfile внутри ./preact_front
    container_name: preact-${ALIASE}
    expose:
      - "80"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
    restart: unless-stopped
    networks:
      - internal-net
      - shared_network
  
  # только тут нужно поменять имя сервиса
  pgbouncer-xeon:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    image: edoburu/pgbouncer:latest
    environment:
      DB_HOST: ${POSTGRES_HOST}-${ALIASE}
      DB_PORT: 5432
      DB_USER: ${POSTGRES_USER}  # wine
      DB_PASSWORD: ${POSTGRES_PASSWORD}  # wine1
      DB_NAME: ${POSTGRES_DB}  # wine_db
      AUTH_TYPE: scram-sha-256
      POOL_MODE: transaction
      MAX_CLIENT_CONN: 500
      SERVER_IDLE_TIMEOUT: 600
      QUERY_TIMEOUT: 60
      DEFAULT_POOL_SIZE: 50
      MIN_POOL_SIZE: 20
      RESERVE_POOL_SIZE: 10
      LISTEN_PORT: 6432
      ADMIN_USERS: ${POSTGRES_USER}
      # ВАЖНО: Явно создаем userlist через переменные
      AUTH_FILE: /etc/pgbouncer/userlist.txt
      # Дополнительные пользователи (если нужны)
      USERS: "${POSTGRES_USER} ${POSTGRES_PASSWORD}"
    expose:
      - "6432"  # Порт для приложения
    restart: unless-stopped
    healthcheck:
      # Официальный способ проверки pgbouncer (внутри образа есть psql-client)
      test: ["CMD", "pg_isready", "-h", "localhost", "-p", "6432", "-U", "${POSTGRES_USER}", "-d", "${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5
    depends_on:
      wine_host:
        condition: service_healthy
    deploy:
      replicas: 4
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    networks:
      - internal-net

  ollama:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер файла лога: 10 МБ
        max-file: "3"     # Количество хранимых файлов ротации: 3
    image: ollama/ollama
    container_name: ollama-${ALIASE}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [ gpu ]
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - internal-net

volumes:
  migration_volume: # alembic migrations
  pg_data: # postgresql data
  pg_dump: # postgres dump/restore
  mongodb_data:
  upload_volume:
  certs_data:
  certbot_www:
  ollama_data:

networks:
  internal-net: # Изолированная сеть для базы и прокси
  shared_network:
    external: true